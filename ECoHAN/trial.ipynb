{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harunachal/anaconda3/envs/llm/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3577: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel , Field\n",
    "from langchain_ollama import OllamaLLM  \n",
    "model = OllamaLLM(model = 'llama3.2' , temperature=0.1  , base_url='http://shinigami:11111')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class robot_output(BaseModel):\n",
    "    speak_to_human : bool = Field(description=\"set to true if there is a need for speaking with human\" , default=True)\n",
    "    output : str = Field(description=\"the sentence, the robot needs to speak to the human\")\n",
    "    mode : str  = Field(description=\"The navigation mode the robot needs to switch to  (back_off , move_forward)\" , default=\"back_off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open('ecohan/config/conversation.yaml' , 'r' ) as f :\n",
    "    yaml_data = yaml.safe_load(f) \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conversation_robot_listener': {'task': 'you are a AI bot controlling navigation and speech strategies of a robot in a evironment with human moving. The humans you interact with might be in a hurry or relaxed. \\nbased on human speech you need to understand their urgency, the robot has two navigation options 1) move forward (makes the robot continue its predefined task), 2) back off (blocks the robot from doing its task, allowing human to go first) \\nyou must wisely choose one of these based on the level of urgency of the human. Pass the navigation strategy of \\neither back off or move forward in the \"mode\" output field (required).optionally you can also decide to speak \\nto the human about the situation. if you decide to speak, turn the \"speak_to_human\" output field to true, and fill in \"speech\" output field with the sentence that is socially acceptable to speak to a human.\\nIf the human is passing urgent, you should back_off, and if they are relaxed or allow you to go, you should move forward. you can be pro active in some cases.\\nThe human has said \"{human_speech}\".The intended output format is {output_format}, \\nyou should only produce the intended json dictionary. you should not produce python script. \\n',\n",
       "  'output_format': '{\\n  \"speak_to_human\" : \"True if there is a need to speak to human\",\\n  \"speech\"  : \"sentence to speak to the human\",\\n  \"mode\" : \"type of navigation mode intended. (Required Field)\"\\n}\\n'}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yaml_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = JsonOutputParser(pydantic_object=robot_output)\n",
    "task= yaml_data['conversation_robot_listener']['task']\n",
    "output_format = yaml_data['conversation_robot_listener']['output_format']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(task )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['human_speech', 'output_format'], input_types={}, partial_variables={}, template='you are a AI bot controlling navigation and speech strategies of a robot in a evironment with human moving. The humans you interact with might be in a hurry or relaxed. \\nbased on human speech you need to understand their urgency, the robot has two navigation options 1) move forward (makes the robot continue its predefined task), 2) back off (blocks the robot from doing its task, allowing human to go first) \\nyou must wisely choose one of these based on the level of urgency of the human. Pass the navigation strategy of \\neither back off or move forward in the \"mode\" output field (required).optionally you can also decide to speak \\nto the human about the situation. if you decide to speak, turn the \"speak_to_human\" output field to true, and fill in \"speech\" output field with the sentence that is socially acceptable to speak to a human.\\nIf the human is passing urgent, you should back_off, and if they are relaxed or allow you to go, you should move forward. you can be pro active in some cases.\\nThe human has said \"{human_speech}\".The intended output format is {output_format}, \\nyou should only produce the intended json dictionary. you should not produce python script. \\n')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"speak_to_human\" : \"True if there is a need to speak to human\",\\n  \"speech\"  : \"sentence to speak to the human\",\\n  \"mode\" : \"type of navigation mode intended. (Required Field)\"\\n}\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt |  model | parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_response = chain.invoke({'human_speech'  : 'you can proceed' , 'output_format' : output_format })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'speak_to_human': False, 'speech': '', 'mode': 'move forward'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
